<!DOCTYPE HTML>
<html>
	
<head>
	<meta charset="utf-8">
	<title>CVPR 2022: Deep Unlearning via Randomized Conditionally Independent Hessians</title>
	<link href='https://fonts.googleapis.com/css?family=Roboto' rel='stylesheet' type='text/css'>
	<link rel="stylesheet" href="../../css/title-bar.css">
	<link rel="stylesheet" href="../../css/main.css">
	<script src="https://code.jquery.com/jquery-3.2.1.js"></script>
	<link rel="stylesheet" href="css/main.css">
	<script src=d3.v4.min.js></script>
	<script src="topojson.v2.min.js" charset="utf-8"></script>
	<script src="main.js"></script>
	<script> 
		$(function(){
	  		$(".header").load("../../header.html"); 
		});
	</script> 
</head>


<body>
	<div id="header" class="header"></div>
	<div class="content">
		<div class="container">
			<div id="myheader">
		    	<h1>Deep Unlearning via Randomized Conditionally Independent Hessians</h1>
		    	<h5><br/></h5>
		    	<h2>CVPR 2022</h2>
		    	<h3>Ronak Mehta, Sourav Pal, Sathya Ravi, Vikas Singh</h3>
		 	</div>
			<div class="row clearfix">
			<hr class="style1" style="margin-top: 25px"/>

		  <div class="row" style="margin-top: 25px">
		      <div class="column left">
		        <h2>Abstract</h2>
		        <p>Recent legislation has led to interest in machine unlearning, i.e., removing specific training samples from a predictive model as if they never existed in the training
		dataset. Unlearning may also be required due to corrupted/adversarial data or simply a userâ€™s updated privacy requirement. For models which require no training (k-NN), simply deleting the closest original sample can be effective. But this idea is inapplicable to models which learn richer representations. Recent ideas leveraging optimization-based updates scale poorly with the model dimension d, due to inverting the Hessian of the loss function. We use a variant of a new conditional independence coefficient, L-CODEC, to identify a subset of the model parameters with the most semantic overlap on an individual sample level. Our approach completely avoids the need to invert a (possibly) huge matrix. By utilizing a Markov blanket selection common in the literature, we premise that L-CODEC is also suitable for deep unlearning, as well as other applications in vision. Compared to alternatives, L-CODEC makes approximate unlearning possible in settings that would otherwise be infeasible, including vision models used for face recognition, person re-identification and NLP models that may require unlearning data identified for exclusion.</p>
		        <br/>
		      </div>
		    <div class = "column right">
		      <h2>Approximate Unlearning</h2>
		      <br/><br/>
		      <img src="images/layercnn.png" alt="Unlearning Figure" style="width:95%;height=auto;">
		      <img src="images/lfoci_pipeline.png" alt="Unlearning Figure" style="width:95%;height=auto;">
		      <p> Specific subnetworks (layers, kernels or filters, slices, etc.) are associated with particular samples or sample space regions. Using L-FOCI, we can identify these subnetworks and restrict updates to them, enabling efficient unlearning.</p>
		    </div>
		  </div>

		  <hr class="style1" style="margin-top: 25px"/>
		  <div class="row" style="margin-top: 25px">
		    <div class="column center">
		      <h2>Video</h2>
		    </div>
		  </div>

		  <hr class="style1" style="margin-top: 25px"/>
		  <div class="row" style="margin-top: 25px">
		    <div class="column left">
		        <h2>Reference</h2>
		        <br/>
		      </div>
		    <div class = "column right">
		      <h2>Code</h2>
		    </div>
		    <hr class="style1" style="margin-top: 25px"/>
		  	</div>
				<h2>Acknowledgements</h2>
				<p> This work was supported by NIH grants RF1AG059312, RF1AG062336 and RF1AG059869, NSF award CCF 1918211 and funds from the American Family Insurance Data Science Institute at UW-Madison. Sathya Ravi was supported by UIC-ICR start-up funds.
            	</p>
			</div>
		</div>


</body>

</html>
